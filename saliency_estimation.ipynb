{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "from scipy.ndimage import convolve\n",
    "from scipy.signal import wiener\n",
    "from skimage import img_as_float\n",
    "from skimage import img_as_float, img_as_ubyte"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute Saliency based on Laplacian and Wiener filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Function to create a directory if it doesn't exist\n",
    "def create_directory(directory):\n",
    "    if not os.path.exists(directory):\n",
    "        os.makedirs(directory)\n",
    "\n",
    "# Specify the folder containing the videos\n",
    "input_folder = '/replay_dataset_saliency/test/real'  # Replace with the actual folder path\n",
    "output_folder = '/replay_dataset_saliency/test/real_com_sil'  # Replace with the output folder path\n",
    "\n",
    "# Get a list of all video files in the folder\n",
    "video_files = [f for f in os.listdir(input_folder) if f.endswith(('.avi', '.mp4', '.mov'))]  # Change the extensions as necessary\n",
    "\n",
    "# Loop through each video file\n",
    "for video_file in video_files:\n",
    "    # Read the video file\n",
    "    video_path = os.path.join(input_folder, video_file)\n",
    "    video = cv2.VideoCapture(video_path)\n",
    "    \n",
    "    # Create a folder for saving images\n",
    "    video_name = os.path.splitext(video_file)[0]\n",
    "    create_directory(os.path.join(output_folder, video_name))\n",
    "    \n",
    "    # Read the first frame\n",
    "    ret, first_frame = video.read()\n",
    "    if not ret:\n",
    "        print(f\"Failed to read the video file: {video_file}\")\n",
    "        continue\n",
    "\n",
    "    # Initialize variables for averaging\n",
    "    sum_frames = np.float64(first_frame)\n",
    "    frame_count = 1\n",
    "    \n",
    "    # Read and accumulate frames from the video\n",
    "    while True:\n",
    "        ret, frame = video.read()\n",
    "        if not ret:\n",
    "            break\n",
    "        sum_frames += np.float64(frame)\n",
    "        frame_count += 1\n",
    "\n",
    "    # Calculate the average frame\n",
    "    average_frame = np.uint8(sum_frames / frame_count)\n",
    "\n",
    "    # Normalize the images\n",
    "    first_frame = img_as_float(first_frame)\n",
    "    average_frame = img_as_float(average_frame)\n",
    "\n",
    "    # Define the Laplacian filter\n",
    "    Laplacian = np.array([[0, 1, 0], [1, -4, 1], [0, 1, 0]])\n",
    "\n",
    "    # Apply the Laplacian filter to the first image\n",
    "    noisyR, noisyG, noisyB = cv2.split(first_frame)\n",
    "    denoisedR = convolve(noisyR, Laplacian)\n",
    "    denoisedG = convolve(noisyG, Laplacian)\n",
    "    denoisedB = convolve(noisyB, Laplacian)\n",
    "    Filtering1 = cv2.merge([denoisedR, denoisedG, denoisedB])\n",
    "\n",
    "    # Apply Wiener filter to the first image\n",
    "    noisyR = noisyR + np.random.normal(0, 0.005, noisyR.shape)\n",
    "    denoisedR = wiener(noisyR, (15, 15))\n",
    "    noisyG = noisyG + np.random.normal(0, 0.005, noisyG.shape)\n",
    "    denoisedG = wiener(noisyG, (15, 15))\n",
    "    noisyB = noisyB + np.random.normal(0, 0.005, noisyB.shape)\n",
    "    denoisedB = wiener(noisyB, (15, 15))\n",
    "    Filtering2 = cv2.merge([denoisedR, denoisedG, denoisedB])\n",
    "\n",
    "    # Saliency estimation for the first image\n",
    "    Saliency1 = (Filtering1 - Filtering2) ** 2\n",
    "    d1 = first_frame - Filtering1\n",
    "\n",
    "    # Apply the Laplacian filter to the second image (average frame)\n",
    "    noisyR, noisyG, noisyB = cv2.split(average_frame)\n",
    "    denoisedR = convolve(noisyR, Laplacian)\n",
    "    denoisedG = convolve(noisyG, Laplacian)\n",
    "    denoisedB = convolve(noisyB, Laplacian)\n",
    "    b2 = cv2.merge([denoisedR, denoisedG, denoisedB])\n",
    "\n",
    "    # Apply Wiener filter to the second image\n",
    "    noisyR = noisyR + np.random.normal(0, 0.005, noisyR.shape)\n",
    "    denoisedR = wiener(noisyR, (15, 15))\n",
    "    noisyG = noisyG + np.random.normal(0, 0.005, noisyG.shape)\n",
    "    denoisedG = wiener(noisyG, (15, 15))\n",
    "    noisyB = noisyB + np.random.normal(0, 0.005, noisyB.shape)\n",
    "    denoisedB = wiener(noisyB, (15, 15))\n",
    "    Image2 = cv2.merge([denoisedR, denoisedG, denoisedB])\n",
    "\n",
    "    # Saliency estimation for the second image\n",
    "    Saliency2 = (b2 - Image2) ** 2\n",
    "    d2 = average_frame - b2\n",
    "\n",
    "    # Weights normalization\n",
    "    weight1 = Saliency1 / (Saliency1 + Saliency2 + 1e-6)  # Adding a small value to avoid division by zero\n",
    "    weight2 = Saliency2 / (Saliency1 + Saliency2 + 1e-6)\n",
    "\n",
    "    Finalimag1 = weight1 * d1 + weight2 * d2\n",
    "    finalimage2 = 0.5 * Filtering1 + 0.5 * b2\n",
    "    Fusedframe = Finalimag1 + finalimage2\n",
    "\n",
    "    # Clip and normalize the fused frame before saving\n",
    "    Fusedframe = np.clip(Fusedframe, 0, 1)\n",
    "    Fusedframe = img_as_ubyte(Fusedframe)\n",
    "\n",
    "    # Save the fused frame\n",
    "    fused_frame_filename = os.path.join(output_folder, video_name, f\"{video_name}.jpg\")\n",
    "    cv2.imwrite(fused_frame_filename, Fusedframe)\n",
    "\n",
    "    print(f\"First frame and average frame processed for saliency-based fusion: {video_file}\")\n",
    "\n",
    "print(\"All videos processed.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pt",
   "language": "python",
   "name": "pt"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
